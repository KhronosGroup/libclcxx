//
// Copyright (c) 2015-2016 The Khronos Group Inc.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and/or associated documentation files (the
// "Materials"), to deal in the Materials without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Materials, and to
// permit persons to whom the Materials are furnished to do so, subject to
// the following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Materials.
//
// THE MATERIALS ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
// EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
// IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
// CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
// TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
// MATERIALS OR THE USE OR OTHER DEALINGS IN THE MATERIALS.
//

#pragma once

#include <__ocl_config.h>
#include <__ocl_functions_macros.h>
#include <opencl_type_traits>
#include <__ocl_atomic_enum.h>

namespace cl
{
namespace __spirv
{
MAKE_SPIRV_CALLABLE(OpGroupAll)
MAKE_SPIRV_CALLABLE(OpGroupAny)
MAKE_SPIRV_CALLABLE(OpGroupBroadcast)
MAKE_SPIRV_CALLABLE(OpGroupIAdd)
MAKE_SPIRV_CALLABLE(OpGroupFAdd)
MAKE_SPIRV_CALLABLE(OpGroupSMin)
MAKE_SPIRV_CALLABLE(OpGroupUMin)
MAKE_SPIRV_CALLABLE(OpGroupFMin)
MAKE_SPIRV_CALLABLE(OpGroupSMax)
MAKE_SPIRV_CALLABLE(OpGroupUMax)
MAKE_SPIRV_CALLABLE(OpGroupFMax)

enum GroupOperation
{
    Reduce,
    InclusiveScan,
    ExclusiveScan
};

} //end namespace __spirv

namespace __details
{
template <uint Count> using __size_t_vector_t = make_vector_t<size_t, Count>;
} //end namespace __details

enum class work_group_op    { add, min, max };

template <work_group_op op> int         work_group_reduce(int x)            { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> uint        work_group_reduce(uint x)           { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> long        work_group_reduce(long x)           { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> ulong       work_group_reduce(ulong x)          { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> float       work_group_reduce(float x)          { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
#ifdef cl_khr_fp16
template <work_group_op op> half        work_group_reduce(half x)           { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <work_group_op op> double      work_group_reduce(double x)         { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
#endif //cl_khr_fp64
template <work_group_op op> int         work_group_scan_exclusive(int x)    { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> uint        work_group_scan_exclusive(uint x)   { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> long        work_group_scan_exclusive(long x)   { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> ulong       work_group_scan_exclusive(ulong x)  { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> float       work_group_scan_exclusive(float x)  { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
#ifdef cl_khr_fp16
template <work_group_op op> half        work_group_scan_exclusive(half x)   { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <work_group_op op> double      work_group_scan_exclusive(double x) { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
#endif //cl_khr_fp64
template <work_group_op op> int         work_group_scan_inclusive(int x)    { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> uint        work_group_scan_inclusive(uint x)   { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> long        work_group_scan_inclusive(long x)   { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> ulong       work_group_scan_inclusive(ulong x)  { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> float       work_group_scan_inclusive(float x)  { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
#ifdef cl_khr_fp16
template <work_group_op op> half        work_group_scan_inclusive(half x)   { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <work_group_op op> double      work_group_scan_inclusive(double x) { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
#endif //cl_khr_fp64
template <work_group_op op> int         sub_group_reduce(int x)             { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> uint        sub_group_reduce(uint x)            { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> long        sub_group_reduce(long x)            { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> ulong       sub_group_reduce(ulong x)           { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> float       sub_group_reduce(float x)           { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
#ifdef cl_khr_fp16
template <work_group_op op> half        sub_group_reduce(half x)            { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <work_group_op op> double      sub_group_reduce(double x)          { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
#endif //cl_khr_fp64
template <work_group_op op> int         sub_group_scan_exclusive(int x)     { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> uint        sub_group_scan_exclusive(uint x)    { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> long        sub_group_scan_exclusive(long x)    { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> ulong       sub_group_scan_exclusive(ulong x)   { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> float       sub_group_scan_exclusive(float x)   { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
#ifdef cl_khr_fp16
template <work_group_op op> half        sub_group_scan_exclusive(half x)    { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <work_group_op op> double      sub_group_scan_exclusive(double x)  { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
#endif //cl_khr_fp64
template <work_group_op op> int         sub_group_scan_inclusive(int x)     { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> uint        sub_group_scan_inclusive(uint x)    { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> long        sub_group_scan_inclusive(long x)    { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> ulong       sub_group_scan_inclusive(ulong x)   { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
template <work_group_op op> float       sub_group_scan_inclusive(float x)   { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
#ifdef cl_khr_fp16
template <work_group_op op> half        sub_group_scan_inclusive(half x)    { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <work_group_op op> double      sub_group_scan_inclusive(double x)  { static_assert(__details::__always_false<conditional_t<op == work_group_op::add, int, float>>::value, "Internal error: unhandled enum specialization."); }
#endif //cl_khr_fp64



__ALWAYS_INLINE bool         work_group_all                                      (bool predicate)                                                    { return __spirv::__make_OpGroupAll_call           <bool>(__spirv::Workgroup, predicate); }
__ALWAYS_INLINE bool         work_group_any                                      (bool predicate)                                                    { return __spirv::__make_OpGroupAny_call           <bool>(__spirv::Workgroup, predicate); }
__ALWAYS_INLINE int          work_group_broadcast                                (int a, size_t local_id)                                            { return __spirv::__make_OpGroupBroadcast_call      <int>(__spirv::Workgroup, a, local_id); }
__ALWAYS_INLINE uint         work_group_broadcast                                (uint a, size_t local_id)                                           { return __spirv::__make_OpGroupBroadcast_call     <uint>(__spirv::Workgroup, a, local_id); }
__ALWAYS_INLINE long         work_group_broadcast                                (long a, size_t local_id)                                           { return __spirv::__make_OpGroupBroadcast_call     <long>(__spirv::Workgroup, a, local_id); }
__ALWAYS_INLINE ulong        work_group_broadcast                                (ulong a, size_t local_id)                                          { return __spirv::__make_OpGroupBroadcast_call    <ulong>(__spirv::Workgroup, a, local_id); }
 __ALWAYS_INLINE float       work_group_broadcast                                (float a, size_t local_id)                                          { return __spirv::__make_OpGroupBroadcast_call    <float>(__spirv::Workgroup, a, local_id); }
#ifdef cl_khr_fp16
__ALWAYS_INLINE half         work_group_broadcast                                (half a, size_t local_id)                                           { return __spirv::__make_OpGroupBroadcast_call     <half>(__spirv::Workgroup, a, local_id); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
__ALWAYS_INLINE double       work_group_broadcast                                (double a, size_t local_id)                                         { return __spirv::__make_OpGroupBroadcast_call   <double>(__spirv::Workgroup, a, local_id); }
#endif //cl_khr_fp64
__ALWAYS_INLINE int          work_group_broadcast                                (int a, size_t local_id_x, size_t local_id_y)                       { return __spirv::__make_OpGroupBroadcast_call      <int>(__spirv::Workgroup, a, __details::__size_t_vector_t<2>{ local_id_x, local_id_y }); }
__ALWAYS_INLINE uint         work_group_broadcast                                (uint a, size_t local_id_x, size_t local_id_y)                      { return __spirv::__make_OpGroupBroadcast_call     <uint>(__spirv::Workgroup, a, __details::__size_t_vector_t<2>{ local_id_x, local_id_y }); }
__ALWAYS_INLINE long         work_group_broadcast                                (long a, size_t local_id_x, size_t local_id_y)                      { return __spirv::__make_OpGroupBroadcast_call     <long>(__spirv::Workgroup, a, __details::__size_t_vector_t<2>{ local_id_x, local_id_y }); }
__ALWAYS_INLINE ulong        work_group_broadcast                                (ulong a, size_t local_id_x, size_t local_id_y)                     { return __spirv::__make_OpGroupBroadcast_call    <ulong>(__spirv::Workgroup, a, __details::__size_t_vector_t<2>{ local_id_x, local_id_y }); }
 __ALWAYS_INLINE float       work_group_broadcast                                (float a, size_t local_id_x, size_t local_id_y)                     { return __spirv::__make_OpGroupBroadcast_call    <float>(__spirv::Workgroup, a, __details::__size_t_vector_t<2>{ local_id_x, local_id_y }); }
#ifdef cl_khr_fp16
__ALWAYS_INLINE half         work_group_broadcast                                (half a, size_t local_id_x, size_t local_id_y)                      { return __spirv::__make_OpGroupBroadcast_call     <half>(__spirv::Workgroup, a, __details::__size_t_vector_t<2>{ local_id_x, local_id_y }); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
__ALWAYS_INLINE double       work_group_broadcast                                (double a, size_t local_id_x, size_t local_id_y)                    { return __spirv::__make_OpGroupBroadcast_call   <double>(__spirv::Workgroup, a, __details::__size_t_vector_t<2>{ local_id_x, local_id_y }); }
#endif //cl_khr_fp64
__ALWAYS_INLINE int          work_group_broadcast                                (int a, size_t local_id_x, size_t local_id_y, size_t local_id_z)    { return __spirv::__make_OpGroupBroadcast_call      <int>(__spirv::Workgroup, a, __details::__size_t_vector_t<3>{ local_id_x, local_id_y, local_id_z }); }
__ALWAYS_INLINE uint         work_group_broadcast                                (uint a, size_t local_id_x, size_t local_id_y, size_t local_id_z)   { return __spirv::__make_OpGroupBroadcast_call     <uint>(__spirv::Workgroup, a, __details::__size_t_vector_t<3>{ local_id_x, local_id_y, local_id_z }); }
__ALWAYS_INLINE long         work_group_broadcast                                (long a, size_t local_id_x, size_t local_id_y, size_t local_id_z)   { return __spirv::__make_OpGroupBroadcast_call     <long>(__spirv::Workgroup, a, __details::__size_t_vector_t<3>{ local_id_x, local_id_y, local_id_z }); }
__ALWAYS_INLINE ulong        work_group_broadcast                                (ulong a, size_t local_id_x, size_t local_id_y, size_t local_id_z)  { return __spirv::__make_OpGroupBroadcast_call    <ulong>(__spirv::Workgroup, a, __details::__size_t_vector_t<3>{ local_id_x, local_id_y, local_id_z }); }
 __ALWAYS_INLINE float       work_group_broadcast                                (float a, size_t local_id_x, size_t local_id_y, size_t local_id_z)  { return __spirv::__make_OpGroupBroadcast_call    <float>(__spirv::Workgroup, a, __details::__size_t_vector_t<3>{ local_id_x, local_id_y, local_id_z }); }
#ifdef cl_khr_fp16
__ALWAYS_INLINE half         work_group_broadcast                                (half a, size_t local_id_x, size_t local_id_y, size_t local_id_z)   { return __spirv::__make_OpGroupBroadcast_call     <half>(__spirv::Workgroup, a, __details::__size_t_vector_t<3>{ local_id_x, local_id_y, local_id_z }); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
__ALWAYS_INLINE double       work_group_broadcast                                (double a, size_t local_id_x, size_t local_id_y, size_t local_id_z) { return __spirv::__make_OpGroupBroadcast_call   <double>(__spirv::Workgroup, a, __details::__size_t_vector_t<3>{ local_id_x, local_id_y, local_id_z }); }
#endif //cl_khr_fp64
template <> __ALWAYS_INLINE int          work_group_reduce<work_group_op::add>               (int x)    { return __spirv::__make_OpGroupIAdd_call           <int>(__spirv::Workgroup, __spirv::Reduce, x); }
template <> __ALWAYS_INLINE uint         work_group_reduce<work_group_op::add>               (uint x)   { return __spirv::__make_OpGroupIAdd_call          <uint>(__spirv::Workgroup, __spirv::Reduce, x); }
template <> __ALWAYS_INLINE long         work_group_reduce<work_group_op::add>               (long x)   { return __spirv::__make_OpGroupIAdd_call          <long>(__spirv::Workgroup, __spirv::Reduce, x); }
template <> __ALWAYS_INLINE ulong        work_group_reduce<work_group_op::add>               (ulong x)  { return __spirv::__make_OpGroupIAdd_call         <ulong>(__spirv::Workgroup, __spirv::Reduce, x); }
template <>  __ALWAYS_INLINE float       work_group_reduce<work_group_op::add>               (float x)  { return __spirv::__make_OpGroupFAdd_call         <float>(__spirv::Workgroup, __spirv::Reduce, x); }
#ifdef cl_khr_fp16
template <> __ALWAYS_INLINE half         work_group_reduce<work_group_op::add>               (half x)   { return __spirv::__make_OpGroupFAdd_call          <half>(__spirv::Workgroup, __spirv::Reduce, x); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <> __ALWAYS_INLINE double       work_group_reduce<work_group_op::add>               (double x) { return __spirv::__make_OpGroupFAdd_call        <double>(__spirv::Workgroup, __spirv::Reduce, x); }
#endif //cl_khr_fp64
template <> __ALWAYS_INLINE int          work_group_reduce<work_group_op::min>               (int x)    { return __spirv::__make_OpGroupSMin_call           <int>(__spirv::Workgroup, __spirv::Reduce, x); }
template <> __ALWAYS_INLINE uint         work_group_reduce<work_group_op::min>               (uint x)   { return __spirv::__make_OpGroupUMin_call          <uint>(__spirv::Workgroup, __spirv::Reduce, x); }
template <> __ALWAYS_INLINE long         work_group_reduce<work_group_op::min>               (long x)   { return __spirv::__make_OpGroupSMin_call          <long>(__spirv::Workgroup, __spirv::Reduce, x); }
template <> __ALWAYS_INLINE ulong        work_group_reduce<work_group_op::min>               (ulong x)  { return __spirv::__make_OpGroupUMin_call         <ulong>(__spirv::Workgroup, __spirv::Reduce, x); }
template <>  __ALWAYS_INLINE float       work_group_reduce<work_group_op::min>               (float x)  { return __spirv::__make_OpGroupFMin_call         <float>(__spirv::Workgroup, __spirv::Reduce, x); }
#ifdef cl_khr_fp16
template <> __ALWAYS_INLINE half         work_group_reduce<work_group_op::min>               (half x)   { return __spirv::__make_OpGroupFMin_call          <half>(__spirv::Workgroup, __spirv::Reduce, x); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <> __ALWAYS_INLINE double       work_group_reduce<work_group_op::min>               (double x) { return __spirv::__make_OpGroupFMin_call        <double>(__spirv::Workgroup, __spirv::Reduce, x); }
#endif //cl_khr_fp64
template <> __ALWAYS_INLINE int          work_group_reduce<work_group_op::max>               (int x)    { return __spirv::__make_OpGroupSMax_call           <int>(__spirv::Workgroup, __spirv::Reduce, x); }
template <> __ALWAYS_INLINE uint         work_group_reduce<work_group_op::max>               (uint x)   { return __spirv::__make_OpGroupUMax_call          <uint>(__spirv::Workgroup, __spirv::Reduce, x); }
template <> __ALWAYS_INLINE long         work_group_reduce<work_group_op::max>               (long x)   { return __spirv::__make_OpGroupSMax_call          <long>(__spirv::Workgroup, __spirv::Reduce, x); }
template <> __ALWAYS_INLINE ulong        work_group_reduce<work_group_op::max>               (ulong x)  { return __spirv::__make_OpGroupUMax_call         <ulong>(__spirv::Workgroup, __spirv::Reduce, x); }
template <>  __ALWAYS_INLINE float       work_group_reduce<work_group_op::max>               (float x)  { return __spirv::__make_OpGroupFMax_call         <float>(__spirv::Workgroup, __spirv::Reduce, x); }
#ifdef cl_khr_fp16
template <> __ALWAYS_INLINE half         work_group_reduce<work_group_op::max>               (half x)   { return __spirv::__make_OpGroupFMax_call          <half>(__spirv::Workgroup, __spirv::Reduce, x); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <> __ALWAYS_INLINE double       work_group_reduce<work_group_op::max>               (double x) { return __spirv::__make_OpGroupFMax_call        <double>(__spirv::Workgroup, __spirv::Reduce, x); }
#endif //cl_khr_fp64
template <> __ALWAYS_INLINE int          work_group_scan_exclusive<work_group_op::add>       (int x)    { return __spirv::__make_OpGroupIAdd_call           <int>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
template <> __ALWAYS_INLINE uint         work_group_scan_exclusive<work_group_op::add>       (uint x)   { return __spirv::__make_OpGroupIAdd_call          <uint>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
template <> __ALWAYS_INLINE long         work_group_scan_exclusive<work_group_op::add>       (long x)   { return __spirv::__make_OpGroupIAdd_call          <long>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
template <> __ALWAYS_INLINE ulong        work_group_scan_exclusive<work_group_op::add>       (ulong x)  { return __spirv::__make_OpGroupIAdd_call         <ulong>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
template <>  __ALWAYS_INLINE float       work_group_scan_exclusive<work_group_op::add>       (float x)  { return __spirv::__make_OpGroupFAdd_call         <float>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
#ifdef cl_khr_fp16
template <> __ALWAYS_INLINE half         work_group_scan_exclusive<work_group_op::add>       (half x)   { return __spirv::__make_OpGroupFAdd_call          <half>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <> __ALWAYS_INLINE double       work_group_scan_exclusive<work_group_op::add>       (double x) { return __spirv::__make_OpGroupFAdd_call        <double>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
#endif //cl_khr_fp64
template <> __ALWAYS_INLINE int          work_group_scan_exclusive<work_group_op::min>       (int x)    { return __spirv::__make_OpGroupSMin_call           <int>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
template <> __ALWAYS_INLINE uint         work_group_scan_exclusive<work_group_op::min>       (uint x)   { return __spirv::__make_OpGroupUMin_call          <uint>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
template <> __ALWAYS_INLINE long         work_group_scan_exclusive<work_group_op::min>       (long x)   { return __spirv::__make_OpGroupSMin_call          <long>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
template <> __ALWAYS_INLINE ulong        work_group_scan_exclusive<work_group_op::min>       (ulong x)  { return __spirv::__make_OpGroupUMin_call         <ulong>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
template <>  __ALWAYS_INLINE float       work_group_scan_exclusive<work_group_op::min>       (float x)  { return __spirv::__make_OpGroupFMin_call         <float>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
#ifdef cl_khr_fp16
template <> __ALWAYS_INLINE half         work_group_scan_exclusive<work_group_op::min>       (half x)   { return __spirv::__make_OpGroupFMin_call          <half>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <> __ALWAYS_INLINE double       work_group_scan_exclusive<work_group_op::min>       (double x) { return __spirv::__make_OpGroupFMin_call        <double>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
#endif //cl_khr_fp64
template <> __ALWAYS_INLINE int          work_group_scan_exclusive<work_group_op::max>       (int x)    { return __spirv::__make_OpGroupSMax_call           <int>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
template <> __ALWAYS_INLINE uint         work_group_scan_exclusive<work_group_op::max>       (uint x)   { return __spirv::__make_OpGroupUMax_call          <uint>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
template <> __ALWAYS_INLINE long         work_group_scan_exclusive<work_group_op::max>       (long x)   { return __spirv::__make_OpGroupSMax_call          <long>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
template <> __ALWAYS_INLINE ulong        work_group_scan_exclusive<work_group_op::max>       (ulong x)  { return __spirv::__make_OpGroupUMax_call         <ulong>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
template <>  __ALWAYS_INLINE float       work_group_scan_exclusive<work_group_op::max>       (float x)  { return __spirv::__make_OpGroupFMax_call         <float>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
#ifdef cl_khr_fp16
template <> __ALWAYS_INLINE half         work_group_scan_exclusive<work_group_op::max>       (half x)   { return __spirv::__make_OpGroupFMax_call          <half>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <> __ALWAYS_INLINE double       work_group_scan_exclusive<work_group_op::max>       (double x) { return __spirv::__make_OpGroupFMax_call        <double>(__spirv::Workgroup, __spirv::ExclusiveScan, x); }
#endif //cl_khr_fp64
template <> __ALWAYS_INLINE int          work_group_scan_inclusive<work_group_op::add>       (int x)    { return __spirv::__make_OpGroupIAdd_call           <int>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
template <> __ALWAYS_INLINE uint         work_group_scan_inclusive<work_group_op::add>       (uint x)   { return __spirv::__make_OpGroupIAdd_call          <uint>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
template <> __ALWAYS_INLINE long         work_group_scan_inclusive<work_group_op::add>       (long x)   { return __spirv::__make_OpGroupIAdd_call          <long>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
template <> __ALWAYS_INLINE ulong        work_group_scan_inclusive<work_group_op::add>       (ulong x)  { return __spirv::__make_OpGroupIAdd_call         <ulong>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
template <>  __ALWAYS_INLINE float       work_group_scan_inclusive<work_group_op::add>       (float x)  { return __spirv::__make_OpGroupFAdd_call         <float>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
#ifdef cl_khr_fp16
template <> __ALWAYS_INLINE half         work_group_scan_inclusive<work_group_op::add>       (half x)   { return __spirv::__make_OpGroupFAdd_call          <half>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <> __ALWAYS_INLINE double       work_group_scan_inclusive<work_group_op::add>       (double x) { return __spirv::__make_OpGroupFAdd_call        <double>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
#endif //cl_khr_fp64
template <> __ALWAYS_INLINE int          work_group_scan_inclusive<work_group_op::min>       (int x)    { return __spirv::__make_OpGroupSMin_call           <int>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
template <> __ALWAYS_INLINE uint         work_group_scan_inclusive<work_group_op::min>       (uint x)   { return __spirv::__make_OpGroupUMin_call          <uint>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
template <> __ALWAYS_INLINE long         work_group_scan_inclusive<work_group_op::min>       (long x)   { return __spirv::__make_OpGroupSMin_call          <long>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
template <> __ALWAYS_INLINE ulong        work_group_scan_inclusive<work_group_op::min>       (ulong x)  { return __spirv::__make_OpGroupUMin_call         <ulong>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
template <>  __ALWAYS_INLINE float       work_group_scan_inclusive<work_group_op::min>       (float x)  { return __spirv::__make_OpGroupFMin_call         <float>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
#ifdef cl_khr_fp16
template <> __ALWAYS_INLINE half         work_group_scan_inclusive<work_group_op::min>       (half x)   { return __spirv::__make_OpGroupFMin_call          <half>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <> __ALWAYS_INLINE double       work_group_scan_inclusive<work_group_op::min>       (double x) { return __spirv::__make_OpGroupFMin_call        <double>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
#endif //cl_khr_fp64
template <> __ALWAYS_INLINE int          work_group_scan_inclusive<work_group_op::max>       (int x)    { return __spirv::__make_OpGroupSMax_call           <int>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
template <> __ALWAYS_INLINE uint         work_group_scan_inclusive<work_group_op::max>       (uint x)   { return __spirv::__make_OpGroupUMax_call          <uint>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
template <> __ALWAYS_INLINE long         work_group_scan_inclusive<work_group_op::max>       (long x)   { return __spirv::__make_OpGroupSMax_call          <long>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
template <> __ALWAYS_INLINE ulong        work_group_scan_inclusive<work_group_op::max>       (ulong x)  { return __spirv::__make_OpGroupUMax_call         <ulong>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
template <>  __ALWAYS_INLINE float       work_group_scan_inclusive<work_group_op::max>       (float x)  { return __spirv::__make_OpGroupFMax_call         <float>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
#ifdef cl_khr_fp16
template <> __ALWAYS_INLINE half         work_group_scan_inclusive<work_group_op::max>       (half x)   { return __spirv::__make_OpGroupFMax_call          <half>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <> __ALWAYS_INLINE double       work_group_scan_inclusive<work_group_op::max>       (double x) { return __spirv::__make_OpGroupFMax_call        <double>(__spirv::Workgroup, __spirv::InclusiveScan, x); }
#endif //cl_khr_fp64
__ALWAYS_INLINE bool         sub_group_all                                       (bool predicate)                                                    { return __spirv::__make_OpGroupAll_call           <bool>(__spirv::Subgroup, predicate); }
__ALWAYS_INLINE bool         sub_group_any                                       (bool predicate)                                                    { return __spirv::__make_OpGroupAny_call           <bool>(__spirv::Subgroup, predicate); }
__ALWAYS_INLINE int          sub_group_broadcast                                 (int a, size_t local_id)                                            { return __spirv::__make_OpGroupBroadcast_call      <int>(__spirv::Subgroup, a, local_id); }
__ALWAYS_INLINE uint         sub_group_broadcast                                 (uint a, size_t local_id)                                           { return __spirv::__make_OpGroupBroadcast_call     <uint>(__spirv::Subgroup, a, local_id); }
__ALWAYS_INLINE long         sub_group_broadcast                                 (long a, size_t local_id)                                           { return __spirv::__make_OpGroupBroadcast_call     <long>(__spirv::Subgroup, a, local_id); }
__ALWAYS_INLINE ulong        sub_group_broadcast                                 (ulong a, size_t local_id)                                          { return __spirv::__make_OpGroupBroadcast_call    <ulong>(__spirv::Subgroup, a, local_id); }
 __ALWAYS_INLINE float       sub_group_broadcast                                 (float a, size_t local_id)                                          { return __spirv::__make_OpGroupBroadcast_call    <float>(__spirv::Subgroup, a, local_id); }
#ifdef cl_khr_fp16
__ALWAYS_INLINE half         sub_group_broadcast                                 (half a, size_t local_id)                                           { return __spirv::__make_OpGroupBroadcast_call     <half>(__spirv::Subgroup, a, local_id); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
__ALWAYS_INLINE double       sub_group_broadcast                                 (double a, size_t local_id)                                         { return __spirv::__make_OpGroupBroadcast_call   <double>(__spirv::Subgroup, a, local_id); }
#endif //cl_khr_fp64
__ALWAYS_INLINE int          sub_group_broadcast                                 (int a, size_t local_id_x, size_t local_id_y)                       { return __spirv::__make_OpGroupBroadcast_call      <int>(__spirv::Subgroup, a, __details::__size_t_vector_t<2>{ local_id_x, local_id_y }); }
__ALWAYS_INLINE uint         sub_group_broadcast                                 (uint a, size_t local_id_x, size_t local_id_y)                      { return __spirv::__make_OpGroupBroadcast_call     <uint>(__spirv::Subgroup, a, __details::__size_t_vector_t<2>{ local_id_x, local_id_y }); }
__ALWAYS_INLINE long         sub_group_broadcast                                 (long a, size_t local_id_x, size_t local_id_y)                      { return __spirv::__make_OpGroupBroadcast_call     <long>(__spirv::Subgroup, a, __details::__size_t_vector_t<2>{ local_id_x, local_id_y }); }
__ALWAYS_INLINE ulong        sub_group_broadcast                                 (ulong a, size_t local_id_x, size_t local_id_y)                     { return __spirv::__make_OpGroupBroadcast_call    <ulong>(__spirv::Subgroup, a, __details::__size_t_vector_t<2>{ local_id_x, local_id_y }); }
 __ALWAYS_INLINE float       sub_group_broadcast                                 (float a, size_t local_id_x, size_t local_id_y)                     { return __spirv::__make_OpGroupBroadcast_call    <float>(__spirv::Subgroup, a, __details::__size_t_vector_t<2>{ local_id_x, local_id_y }); }
#ifdef cl_khr_fp16
__ALWAYS_INLINE half         sub_group_broadcast                                 (half a, size_t local_id_x, size_t local_id_y)                      { return __spirv::__make_OpGroupBroadcast_call     <half>(__spirv::Subgroup, a, __details::__size_t_vector_t<2>{ local_id_x, local_id_y }); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
__ALWAYS_INLINE double       sub_group_broadcast                                 (double a, size_t local_id_x, size_t local_id_y)                    { return __spirv::__make_OpGroupBroadcast_call   <double>(__spirv::Subgroup, a, __details::__size_t_vector_t<2>{ local_id_x, local_id_y }); }
#endif //cl_khr_fp64
__ALWAYS_INLINE int          sub_group_broadcast                                 (int a, size_t local_id_x, size_t local_id_y, size_t local_id_z)    { return __spirv::__make_OpGroupBroadcast_call      <int>(__spirv::Subgroup, a, __details::__size_t_vector_t<3>{ local_id_x, local_id_y, local_id_z }); }
__ALWAYS_INLINE uint         sub_group_broadcast                                 (uint a, size_t local_id_x, size_t local_id_y, size_t local_id_z)   { return __spirv::__make_OpGroupBroadcast_call     <uint>(__spirv::Subgroup, a, __details::__size_t_vector_t<3>{ local_id_x, local_id_y, local_id_z }); }
__ALWAYS_INLINE long         sub_group_broadcast                                 (long a, size_t local_id_x, size_t local_id_y, size_t local_id_z)   { return __spirv::__make_OpGroupBroadcast_call     <long>(__spirv::Subgroup, a, __details::__size_t_vector_t<3>{ local_id_x, local_id_y, local_id_z }); }
__ALWAYS_INLINE ulong        sub_group_broadcast                                 (ulong a, size_t local_id_x, size_t local_id_y, size_t local_id_z)  { return __spirv::__make_OpGroupBroadcast_call    <ulong>(__spirv::Subgroup, a, __details::__size_t_vector_t<3>{ local_id_x, local_id_y, local_id_z }); }
 __ALWAYS_INLINE float       sub_group_broadcast                                 (float a, size_t local_id_x, size_t local_id_y, size_t local_id_z)  { return __spirv::__make_OpGroupBroadcast_call    <float>(__spirv::Subgroup, a, __details::__size_t_vector_t<3>{ local_id_x, local_id_y, local_id_z }); }
#ifdef cl_khr_fp16
__ALWAYS_INLINE half         sub_group_broadcast                                 (half a, size_t local_id_x, size_t local_id_y, size_t local_id_z)   { return __spirv::__make_OpGroupBroadcast_call     <half>(__spirv::Subgroup, a, __details::__size_t_vector_t<3>{ local_id_x, local_id_y, local_id_z }); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
__ALWAYS_INLINE double       sub_group_broadcast                                 (double a, size_t local_id_x, size_t local_id_y, size_t local_id_z) { return __spirv::__make_OpGroupBroadcast_call   <double>(__spirv::Subgroup, a, __details::__size_t_vector_t<3>{ local_id_x, local_id_y, local_id_z }); }
#endif //cl_khr_fp64
template <> __ALWAYS_INLINE int          sub_group_reduce<work_group_op::add>                (int x)    { return __spirv::__make_OpGroupIAdd_call           <int>(__spirv::Subgroup, __spirv::Reduce, x); }
template <> __ALWAYS_INLINE uint         sub_group_reduce<work_group_op::add>                (uint x)   { return __spirv::__make_OpGroupIAdd_call          <uint>(__spirv::Subgroup, __spirv::Reduce, x); }
template <> __ALWAYS_INLINE long         sub_group_reduce<work_group_op::add>                (long x)   { return __spirv::__make_OpGroupIAdd_call          <long>(__spirv::Subgroup, __spirv::Reduce, x); }
template <> __ALWAYS_INLINE ulong        sub_group_reduce<work_group_op::add>                (ulong x)  { return __spirv::__make_OpGroupIAdd_call         <ulong>(__spirv::Subgroup, __spirv::Reduce, x); }
template <>  __ALWAYS_INLINE float       sub_group_reduce<work_group_op::add>                (float x)  { return __spirv::__make_OpGroupFAdd_call         <float>(__spirv::Subgroup, __spirv::Reduce, x); }
#ifdef cl_khr_fp16
template <> __ALWAYS_INLINE half         sub_group_reduce<work_group_op::add>                (half x)   { return __spirv::__make_OpGroupFAdd_call          <half>(__spirv::Subgroup, __spirv::Reduce, x); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <> __ALWAYS_INLINE double       sub_group_reduce<work_group_op::add>                (double x) { return __spirv::__make_OpGroupFAdd_call        <double>(__spirv::Subgroup, __spirv::Reduce, x); }
#endif //cl_khr_fp64
template <> __ALWAYS_INLINE int          sub_group_reduce<work_group_op::min>                (int x)    { return __spirv::__make_OpGroupSMin_call           <int>(__spirv::Subgroup, __spirv::Reduce, x); }
template <> __ALWAYS_INLINE uint         sub_group_reduce<work_group_op::min>                (uint x)   { return __spirv::__make_OpGroupUMin_call          <uint>(__spirv::Subgroup, __spirv::Reduce, x); }
template <> __ALWAYS_INLINE long         sub_group_reduce<work_group_op::min>                (long x)   { return __spirv::__make_OpGroupSMin_call          <long>(__spirv::Subgroup, __spirv::Reduce, x); }
template <> __ALWAYS_INLINE ulong        sub_group_reduce<work_group_op::min>                (ulong x)  { return __spirv::__make_OpGroupUMin_call         <ulong>(__spirv::Subgroup, __spirv::Reduce, x); }
template <>  __ALWAYS_INLINE float       sub_group_reduce<work_group_op::min>                (float x)  { return __spirv::__make_OpGroupFMin_call         <float>(__spirv::Subgroup, __spirv::Reduce, x); }
#ifdef cl_khr_fp16
template <> __ALWAYS_INLINE half         sub_group_reduce<work_group_op::min>                (half x)   { return __spirv::__make_OpGroupFMin_call          <half>(__spirv::Subgroup, __spirv::Reduce, x); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <> __ALWAYS_INLINE double       sub_group_reduce<work_group_op::min>                (double x) { return __spirv::__make_OpGroupFMin_call        <double>(__spirv::Subgroup, __spirv::Reduce, x); }
#endif //cl_khr_fp64
template <> __ALWAYS_INLINE int          sub_group_reduce<work_group_op::max>                (int x)    { return __spirv::__make_OpGroupSMax_call           <int>(__spirv::Subgroup, __spirv::Reduce, x); }
template <> __ALWAYS_INLINE uint         sub_group_reduce<work_group_op::max>                (uint x)   { return __spirv::__make_OpGroupUMax_call          <uint>(__spirv::Subgroup, __spirv::Reduce, x); }
template <> __ALWAYS_INLINE long         sub_group_reduce<work_group_op::max>                (long x)   { return __spirv::__make_OpGroupSMax_call          <long>(__spirv::Subgroup, __spirv::Reduce, x); }
template <> __ALWAYS_INLINE ulong        sub_group_reduce<work_group_op::max>                (ulong x)  { return __spirv::__make_OpGroupUMax_call         <ulong>(__spirv::Subgroup, __spirv::Reduce, x); }
template <>  __ALWAYS_INLINE float       sub_group_reduce<work_group_op::max>                (float x)  { return __spirv::__make_OpGroupFMax_call         <float>(__spirv::Subgroup, __spirv::Reduce, x); }
#ifdef cl_khr_fp16
template <> __ALWAYS_INLINE half         sub_group_reduce<work_group_op::max>                (half x)   { return __spirv::__make_OpGroupFMax_call          <half>(__spirv::Subgroup, __spirv::Reduce, x); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <> __ALWAYS_INLINE double       sub_group_reduce<work_group_op::max>                (double x) { return __spirv::__make_OpGroupFMax_call        <double>(__spirv::Subgroup, __spirv::Reduce, x); }
#endif //cl_khr_fp64
template <> __ALWAYS_INLINE int          sub_group_scan_exclusive<work_group_op::add>        (int x)    { return __spirv::__make_OpGroupIAdd_call           <int>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
template <> __ALWAYS_INLINE uint         sub_group_scan_exclusive<work_group_op::add>        (uint x)   { return __spirv::__make_OpGroupIAdd_call          <uint>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
template <> __ALWAYS_INLINE long         sub_group_scan_exclusive<work_group_op::add>        (long x)   { return __spirv::__make_OpGroupIAdd_call          <long>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
template <> __ALWAYS_INLINE ulong        sub_group_scan_exclusive<work_group_op::add>        (ulong x)  { return __spirv::__make_OpGroupIAdd_call         <ulong>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
template <>  __ALWAYS_INLINE float       sub_group_scan_exclusive<work_group_op::add>        (float x)  { return __spirv::__make_OpGroupFAdd_call         <float>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
#ifdef cl_khr_fp16
template <> __ALWAYS_INLINE half         sub_group_scan_exclusive<work_group_op::add>        (half x)   { return __spirv::__make_OpGroupFAdd_call          <half>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <> __ALWAYS_INLINE double       sub_group_scan_exclusive<work_group_op::add>        (double x) { return __spirv::__make_OpGroupFAdd_call        <double>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
#endif //cl_khr_fp64
template <> __ALWAYS_INLINE int          sub_group_scan_exclusive<work_group_op::min>        (int x)    { return __spirv::__make_OpGroupSMin_call           <int>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
template <> __ALWAYS_INLINE uint         sub_group_scan_exclusive<work_group_op::min>        (uint x)   { return __spirv::__make_OpGroupUMin_call          <uint>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
template <> __ALWAYS_INLINE long         sub_group_scan_exclusive<work_group_op::min>        (long x)   { return __spirv::__make_OpGroupSMin_call          <long>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
template <> __ALWAYS_INLINE ulong        sub_group_scan_exclusive<work_group_op::min>        (ulong x)  { return __spirv::__make_OpGroupUMin_call         <ulong>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
template <>  __ALWAYS_INLINE float       sub_group_scan_exclusive<work_group_op::min>        (float x)  { return __spirv::__make_OpGroupFMin_call         <float>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
#ifdef cl_khr_fp16
template <> __ALWAYS_INLINE half         sub_group_scan_exclusive<work_group_op::min>        (half x)   { return __spirv::__make_OpGroupFMin_call          <half>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <> __ALWAYS_INLINE double       sub_group_scan_exclusive<work_group_op::min>        (double x) { return __spirv::__make_OpGroupFMin_call        <double>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
#endif //cl_khr_fp64
template <> __ALWAYS_INLINE int          sub_group_scan_exclusive<work_group_op::max>        (int x)    { return __spirv::__make_OpGroupSMax_call           <int>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
template <> __ALWAYS_INLINE uint         sub_group_scan_exclusive<work_group_op::max>        (uint x)   { return __spirv::__make_OpGroupUMax_call          <uint>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
template <> __ALWAYS_INLINE long         sub_group_scan_exclusive<work_group_op::max>        (long x)   { return __spirv::__make_OpGroupSMax_call          <long>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
template <> __ALWAYS_INLINE ulong        sub_group_scan_exclusive<work_group_op::max>        (ulong x)  { return __spirv::__make_OpGroupUMax_call         <ulong>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
template <>  __ALWAYS_INLINE float       sub_group_scan_exclusive<work_group_op::max>        (float x)  { return __spirv::__make_OpGroupFMax_call         <float>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
#ifdef cl_khr_fp16
template <> __ALWAYS_INLINE half         sub_group_scan_exclusive<work_group_op::max>        (half x)   { return __spirv::__make_OpGroupFMax_call          <half>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <> __ALWAYS_INLINE double       sub_group_scan_exclusive<work_group_op::max>        (double x) { return __spirv::__make_OpGroupFMax_call        <double>(__spirv::Subgroup, __spirv::ExclusiveScan, x); }
#endif //cl_khr_fp64
template <> __ALWAYS_INLINE int          sub_group_scan_inclusive<work_group_op::add>        (int x)    { return __spirv::__make_OpGroupIAdd_call           <int>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
template <> __ALWAYS_INLINE uint         sub_group_scan_inclusive<work_group_op::add>        (uint x)   { return __spirv::__make_OpGroupIAdd_call          <uint>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
template <> __ALWAYS_INLINE long         sub_group_scan_inclusive<work_group_op::add>        (long x)   { return __spirv::__make_OpGroupIAdd_call          <long>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
template <> __ALWAYS_INLINE ulong        sub_group_scan_inclusive<work_group_op::add>        (ulong x)  { return __spirv::__make_OpGroupIAdd_call         <ulong>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
template <>  __ALWAYS_INLINE float       sub_group_scan_inclusive<work_group_op::add>        (float x)  { return __spirv::__make_OpGroupFAdd_call         <float>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
#ifdef cl_khr_fp16
template <> __ALWAYS_INLINE half         sub_group_scan_inclusive<work_group_op::add>        (half x)   { return __spirv::__make_OpGroupFAdd_call          <half>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <> __ALWAYS_INLINE double       sub_group_scan_inclusive<work_group_op::add>        (double x) { return __spirv::__make_OpGroupFAdd_call        <double>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
#endif //cl_khr_fp64
template <> __ALWAYS_INLINE int          sub_group_scan_inclusive<work_group_op::min>        (int x)    { return __spirv::__make_OpGroupSMin_call           <int>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
template <> __ALWAYS_INLINE uint         sub_group_scan_inclusive<work_group_op::min>        (uint x)   { return __spirv::__make_OpGroupUMin_call          <uint>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
template <> __ALWAYS_INLINE long         sub_group_scan_inclusive<work_group_op::min>        (long x)   { return __spirv::__make_OpGroupSMin_call          <long>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
template <> __ALWAYS_INLINE ulong        sub_group_scan_inclusive<work_group_op::min>        (ulong x)  { return __spirv::__make_OpGroupUMin_call         <ulong>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
template <>  __ALWAYS_INLINE float       sub_group_scan_inclusive<work_group_op::min>        (float x)  { return __spirv::__make_OpGroupFMin_call         <float>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
#ifdef cl_khr_fp16
template <> __ALWAYS_INLINE half         sub_group_scan_inclusive<work_group_op::min>        (half x)   { return __spirv::__make_OpGroupFMin_call          <half>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <> __ALWAYS_INLINE double       sub_group_scan_inclusive<work_group_op::min>        (double x) { return __spirv::__make_OpGroupFMin_call        <double>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
#endif //cl_khr_fp64
template <> __ALWAYS_INLINE int          sub_group_scan_inclusive<work_group_op::max>        (int x)    { return __spirv::__make_OpGroupSMax_call           <int>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
template <> __ALWAYS_INLINE uint         sub_group_scan_inclusive<work_group_op::max>        (uint x)   { return __spirv::__make_OpGroupUMax_call          <uint>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
template <> __ALWAYS_INLINE long         sub_group_scan_inclusive<work_group_op::max>        (long x)   { return __spirv::__make_OpGroupSMax_call          <long>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
template <> __ALWAYS_INLINE ulong        sub_group_scan_inclusive<work_group_op::max>        (ulong x)  { return __spirv::__make_OpGroupUMax_call         <ulong>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
template <>  __ALWAYS_INLINE float       sub_group_scan_inclusive<work_group_op::max>        (float x)  { return __spirv::__make_OpGroupFMax_call         <float>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
#ifdef cl_khr_fp16
template <> __ALWAYS_INLINE half         sub_group_scan_inclusive<work_group_op::max>        (half x)   { return __spirv::__make_OpGroupFMax_call          <half>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
#endif //cl_khr_fp16
#ifdef cl_khr_fp64
template <> __ALWAYS_INLINE double       sub_group_scan_inclusive<work_group_op::max>        (double x) { return __spirv::__make_OpGroupFMax_call        <double>(__spirv::Subgroup, __spirv::InclusiveScan, x); }
#endif //cl_khr_fp64


} //end namespace cl